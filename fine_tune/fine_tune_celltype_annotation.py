"""
ScDifformer fine-tuning script for cell annotation tasks.
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict

from datasets import load_from_disk, DatasetDict
from loguru import logger
from sklearn.metrics import accuracy_score, f1_score
from transformers import BertForSequenceClassification, Trainer, TrainingArguments, set_seed


def find_project_root(marker_file: str = "pyproject.toml") -> Path:
    """Locate the project root directory by searching for a marker file.

    Args:
        marker_file: File name that identifies the project root.

    Returns:
        Path to the project root directory.

    Raises:
        FileNotFoundError: If marker file is not found in any parent directory.
    """
    current_dir = Path(__file__).resolve().parent

    while True:
        if (current_dir / marker_file).exists():
            return current_dir

        parent_dir = current_dir.parent

        if parent_dir == current_dir:
            raise FileNotFoundError(f"Could not find {marker_file} in any parent directory")

        current_dir = parent_dir


sys.path.insert(0, str(find_project_root()))

from libs import (
    DataCollatorForCellClassification,
    EXAMPLE_DATASET_DIR,
    EXAMPLE_NAME_ID_PATH,
    CURRENT_MODEL_OUTPUT_DIR,
)  # noqa


@dataclass
class Config:
    organ: str
    task_name: str
    input_dir: str
    pretrain_model_dir: str
    output_dir: str = str(Path(f"{CURRENT_MODEL_OUTPUT_DIR}"))
    batch_size: int = 8
    epochs: int = 3
    lr: float = 5e-5
    seed: int = 2025
    warmup_steps: int = 500
    freeze_layers: int = 0
    num_proc: int = 8
    fp16: bool = True
    gradient_accumulation_steps: int = 1
    early_stop_patience: int = 3

    @staticmethod
    def from_cli() -> "Config":
        # Parse command-line arguments for configuration
        parser = argparse.ArgumentParser()
        parser.add_argument(
            "-on", "--organ", type=str, default="example", help="The organ name (default: example)"
        )
        parser.add_argument(
            "-t",
            "--task_name",
            default="example",
            type=str,
            help="The name of the task (e.g., organ, tissue)",
        )
        parser.add_argument(
            "-id",
            "--input_dir",
            type=str,
            default=EXAMPLE_DATASET_DIR,
            help="The arrow data path, generated by preprocess.py",
        )
        parser.add_argument(
            "-od",
            "--output_dir",
            type=str,
            default=CURRENT_MODEL_OUTPUT_DIR,
            help="The output directory",
        )
        parser.add_argument(
            "-pmd",
            "--pretrain_model_dir",
            type=str,
            required=True,
            help="The pretrained model directory",
        )
        parser.add_argument(
            "-sd",
            "--seed",
            type=int,
            default=2025,
            help="Random seed for numpy, torch, etc (default: 2025)",
        )
        parser.add_argument(
            "-nip",
            "--name_id_path",
            type=str,
            default=EXAMPLE_NAME_ID_PATH,
            help="The name id file directory",
        )
        parser.add_argument(
            "-gn", "--gpu_number", type=int, default=1, help="Number of GPUs to use (default: 1)"
        )
        parser.add_argument(
            "-fc",
            "--fold_count",
            type=int,
            default=1,
            help="Number of folds for training (default: 1)",
        )
        parser.add_argument(
            "-ml",
            "--max_lr",
            type=float,
            default=5e-5,
            help="Maximum learning rate (default: 5e-5)",
        )
        parser.add_argument(
            "-np", "--num_proc", type=int, default=8, help="Number of CPU cores to use (default: 8)"
        )
        parser.add_argument(
            "-e", "--epochs", type=int, default=3, help="Number of training epochs (default: 3)"
        )
        parser.add_argument(
            "-bs",
            "--batch_size",
            type=int,
            default=4,
            help="Batch size for training and eval (default: 4)",
        )
        parser.add_argument(
            "-mis",
            "--max_input_size",
            type=int,
            default=2**11,
            help="Maximum input token size (default: 2048)",
        )
        parser.add_argument(
            "-fl",
            "--freeze_layers",
            type=int,
            default=0,
            help="Number of model layers to freeze (default: 0)",
        )
        parser.add_argument(
            "-ws",
            "--warmup_steps",
            type=int,
            default=500,
            help="Number of warmup steps (default: 500)",
        )
        parser.add_argument(
            "-lsf",
            "--lr_schedule_fn",
            type=str,
            default="linear",
            help="Learning rate schedule function (default: linear)",
        )
        parser.add_argument(
            "-o", "--optimizer", type=str, default="adamw", help="Optimizer to use (default: adamw)"
        )
        args = parser.parse_args()
        # Initialize Config with parsed args, handling defaults and paths
        cfg = Config(
            organ=args.organ,
            task_name=args.task_name,
            input_dir=str(Path(args.input_dir)),
            pretrain_model_dir=str(Path(args.pretrain_model_dir)),
            output_dir=str(Path(args.output_dir or f"./output/{args.task_name}/{args.organ}")),
            batch_size=args.batch_size,
            epochs=args.epochs,
            lr=args.max_lr,
            seed=args.seed,
            warmup_steps=args.warmup_steps,
            freeze_layers=args.freeze_layers,
            num_proc=args.num_proc,
        )
        return cfg


def compute_metrics(pred):
    # Compute evaluation metrics: accuracy, macro F1
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    metrics = {
        "accuracy": accuracy_score(labels, preds),
        "macro_f1": f1_score(labels, preds, average="macro"),
    }
    return metrics


def build_dataset(cfg: Config) -> tuple[DatasetDict, Dict[str, int]]:
    # Load and shuffle dataset from disk
    ds = load_from_disk(str(cfg.input_dir)).shuffle(seed=cfg.seed)
    # Rename 'cell_type' column to 'label'
    ds = ds.rename_column("cell_type", "label")

    # Create unique label mappings (name to ID and ID to name)
    target_names = sorted(set(ds["label"]))
    name2id = {n: i for i, n in enumerate(target_names)}
    id2name = {i: n for n, i in name2id.items()}

    # Map string labels to integer IDs
    ds = ds.map(lambda x: {"label": name2id[x["label"]]}, num_proc=cfg.num_proc)

    # Split dataset into train (80%) and test (20%)
    ds = ds.train_test_split(test_size=0.2, seed=cfg.seed)

    # Save ID-to-name mapping to JSON file
    (Path(cfg.output_dir) / "id2name.json").write_text(json.dumps(id2name, indent=2))
    return ds, name2id


def build_model(cfg: Config, num_labels: int) -> BertForSequenceClassification:
    # Load pretrained BERT model for sequence classification
    model = BertForSequenceClassification.from_pretrained(
        str(cfg.pretrain_model_dir),
        num_labels=num_labels,
        output_attentions=False,
        output_hidden_states=False,
    )
    # Freeze specified number of initial layers if required
    if cfg.freeze_layers > 0:
        for layer in model.bert.encoder.layer[: cfg.freeze_layers]:
            layer.requires_grad_(False)
    return model


def train(cfg: Config):
    # Set random seed for reproducibility
    set_seed(cfg.seed)
    # Create output directory and save config
    Path(cfg.output_dir).mkdir(parents=True, exist_ok=True)
    (Path(cfg.output_dir) / "config.json").write_text(json.dumps(asdict(cfg), indent=2))

    # Build dataset and label mappings
    ds, name2id = build_dataset(cfg)
    # Build model with appropriate number of labels
    model = build_model(cfg, num_labels=len(name2id))

    # Calculate logging steps based on dataset size
    steps_per_epoch = len(ds["train"]) // (cfg.batch_size * cfg.gradient_accumulation_steps)
    logging_steps = max(1, steps_per_epoch // 10)

    # Configure training arguments
    args = TrainingArguments(
        num_train_epochs=cfg.epochs,
        do_train=True,
        do_eval=True,
        output_dir=str(cfg.output_dir),
        per_device_train_batch_size=cfg.batch_size,
        per_device_eval_batch_size=cfg.batch_size,
        gradient_accumulation_steps=cfg.gradient_accumulation_steps,
        learning_rate=cfg.lr,
        warmup_steps=cfg.warmup_steps,
        logging_steps=logging_steps,
        save_strategy="epoch",
        eval_strategy="epoch",
        load_best_model_at_end=True,
        metric_for_best_model="macro_f1",
        fp16=cfg.fp16,
        dataloader_num_workers=cfg.num_proc,
    )

    # Initialize Trainer with model, args, datasets, and custom collator
    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=ds["train"],
        eval_dataset=ds["test"],
        compute_metrics=compute_metrics,
        data_collator=DataCollatorForCellClassification(),
    )

    logger.info("ðŸš€ Start training ...")
    # Perform training
    trainer.train()
    # Save the best model
    trainer.save_model(os.path.join(cfg.output_dir, cfg.organ))
    logger.info("âœ… Training finished successfully!")


if __name__ == "__main__":
    cfg = Config.from_cli()
    train(cfg)
