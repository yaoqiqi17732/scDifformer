{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e4eab2-81e8-4049-989f-b9e15ff4ca55",
   "metadata": {},
   "source": [
    "## 验证实验：dixit数据看cos夹角"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f7325-1684-4f53-82fc-94bfb2d5586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneformer import InSilicoPerturber\n",
    "from geneformer import InSilicoPerturberStats\n",
    "from geneformer.tokenizer import TOKEN_DICTIONARY_FILE\n",
    "from datasets import concatenate_datasets\n",
    "import itertools as it\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns; sns.set()\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, load_from_disk\n",
    "from tqdm.notebook import trange\n",
    "from transformers import BertForMaskedLM, BertForTokenClassification, BertForSequenceClassification\n",
    "from collections import OrderedDict\n",
    "from geneformer.in_silico_perturber import downsample_and_sort, \\\n",
    "                                         gen_attention_mask, \\\n",
    "                                         get_model_input_size, \\\n",
    "                                         load_and_filter, \\\n",
    "                                         load_model, \\\n",
    "                                         pad_tensor_list, \\\n",
    "                                         quant_layers, \\\n",
    "                                         pad_tensor, \\\n",
    "                                                                                                                                                                                                                                                                                                                                                                         forward_pass_single_cell, \\\n",
    "                                         make_perturbation_batch, \\\n",
    "                                         quant_cos_sims, \\\n",
    "                                         make_comparison_batch, \\\n",
    "                                         measure_length, \\\n",
    "                                         delete_indices, \\\n",
    "                                         pad_or_truncate_encoding, \\\n",
    "                                         remove_indices_from_emb_batch, \\\n",
    "                                         get_cell_state_avg_embs, \\\n",
    "                                         overexpress_tokens, \\\n",
    "                                         cos_sim_shift, \\\n",
    "                                         mean_nonpadding_embs\n",
    "\n",
    "from collections import Counter\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "from transformers import Trainer\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pandas import Series,DataFrame\n",
    "import random\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04adf04-ada7-4570-b772-760aa6a08845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改的函数， 在geneformer代码的基础上做的修改，不然代码跑不通\n",
    "def get_possible_states(cell_states_to_model):\n",
    "    possible_states = []\n",
    "    for key in [\"start_state\",\"goal_state\"]:\n",
    "        possible_states += [cell_states_to_model[key]]\n",
    "    return possible_states\n",
    "\n",
    "def random_select(input, max_sample=500, seed=2023):\n",
    "    random.seed(seed)\n",
    "    if len(input) <= max_sample:\n",
    "        return input\n",
    "    else:\n",
    "        random_list = random.sample(list(np.arange(len(input))), max_sample)\n",
    "        return input.select(random_list)\n",
    "\n",
    "def cos_sim_shift_ipsc(original_emb, \n",
    "                      minibatch_emb, \n",
    "                      end_emb, \n",
    "                      perturb_group, \n",
    "                      original_minibatch_lengths = None, \n",
    "                      minibatch_lengths = None,\n",
    "                      perturb_method = 'cell'):\n",
    "    cos = torch.nn.CosineSimilarity(dim=2)\n",
    "    \n",
    "    if original_emb.size() != minibatch_emb.size():\n",
    "        logger.error(\n",
    "            f\"Embeddings are not the same dimensions. \" \\\n",
    "            f\"original_emb is {original_emb.size()}. \" \\\n",
    "            f\"minibatch_emb is {minibatch_emb.size()}. \"\n",
    "        )\n",
    "        raise\n",
    "    \n",
    "    if perturb_method == 'cell':\n",
    "        if original_minibatch_lengths is not None:\n",
    "            original_emb = mean_nonpadding_embs(original_emb, original_minibatch_lengths)\n",
    "            end_emb = torch.unsqueeze(end_emb, 1)\n",
    "            origin_v_end = cos(original_emb, end_emb)\n",
    "            origin_v_end = torch.squeeze(origin_v_end)\n",
    "        \n",
    "        if minibatch_lengths is not None:\n",
    "            perturb_emb = mean_nonpadding_embs(minibatch_emb, minibatch_lengths)\n",
    "            perturb_v_end = cos(perturb_emb, end_emb)\n",
    "            perturb_v_end = torch.squeeze(perturb_v_end)\n",
    "    elif perturb_method == 'gene':\n",
    "        origin_v_end = cos(original_emb, end_emb)\n",
    "        perturb_v_end = cos(minibatch_emb, end_emb)\n",
    "    \n",
    "    return [(perturb_v_end - origin_v_end).to('cpu')], [((perturb_v_end - origin_v_end) / origin_v_end * 100).to('cpu')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66ecc8-8e98-4b70-a355-f5f7f40c9053",
   "metadata": {},
   "source": [
    "### 1. 变量设定\n",
    "* perturb_genes = 'YY1'\n",
    "* perturb_ensembl_id = ['ENSG00000100811']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e246ee67-19c4-4b56-a1ab-204974ba43ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ENSG00000100811']\n"
     ]
    }
   ],
   "source": [
    "perturb_type=\"delete\" # perturb的类型设置为overexpress\n",
    "perturb_rank_shift=None \n",
    "genes_to_perturb = ['ENSG00000100811'] # 需要perturb的gene 的ensembl_id\n",
    "# random.seed(0)\n",
    "# genes_to_perturb = random.sample(list(gene_token_dict.keys())[2:], 5) # random\n",
    "print(genes_to_perturb)\n",
    "combos=0\n",
    "anchor_gene=None\n",
    "model_type=\"diffusion_12L\" # 用的什么模型要指出来，取源文件里面找\n",
    "num_classes = 1\n",
    "emb_mode=\"cell_and_gene\"\n",
    "cell_emb_style=\"mean_pool\"\n",
    "#filter_data={\"cell_type\":['fibroblast']}\n",
    "filter_data=None\n",
    "cell_states_to_model={'state_key': 'condition',\n",
    "                      'start_state': 'control', \n",
    "                      'goal_state': 'YY1'} #是什么状态要说明\n",
    "max_ncells=2000\n",
    "#cell_inds_to_perturb={'start':0, 'end':500}\n",
    "cell_inds_to_perturb='all'\n",
    "emb_layer=-1\n",
    "forward_batch_size=100 #batchsize要好好设定，不能超出内存\n",
    "nproc=16\n",
    "token_dictionary_file=TOKEN_DICTIONARY_FILE\n",
    "\n",
    "if genes_to_perturb == \"all\":\n",
    "    perturb_group = False\n",
    "else:\n",
    "    perturb_group = True\n",
    "    if (anchor_gene != None) or (combos != 0):\n",
    "        anchor_gene = None\n",
    "        combos = 0\n",
    "        logger.warning( \n",
    "            \"anchor_gene set to None and combos set to 0. \" \\\n",
    "            \"If providing list of genes to perturb, \" \\\n",
    "            \"list of genes_to_perturb will be perturbed together, \"\\\n",
    "            \"without anchor gene or combinations.\")\n",
    "        \n",
    "# load token dictionary (Ensembl IDs:token)\n",
    "with open(token_dictionary_file, \"rb\") as f:\n",
    "    gene_token_dict = pickle.load(f)\n",
    "pad_token_id = gene_token_dict.get(\"<pad>\")\n",
    "\n",
    "if anchor_gene is None:\n",
    "    anchor_token = None\n",
    "else:\n",
    "    try:\n",
    "        anchor_token = [gene_token_dict[anchor_gene]]\n",
    "    except KeyError:\n",
    "        logger.error(\n",
    "            f\"Anchor gene {anchor_gene} not in token dictionary.\"\n",
    "        )\n",
    "        raise\n",
    "\n",
    "if genes_to_perturb == \"all\":\n",
    "    tokens_to_perturb = \"all\"\n",
    "else:\n",
    "    missing_genes = [gene for gene in genes_to_perturb if gene not in gene_token_dict.keys()]\n",
    "    if len(missing_genes) == len(genes_to_perturb):\n",
    "        logger.error(\n",
    "            \"None of the provided genes to perturb are in token dictionary.\"\n",
    "        )\n",
    "        raise\n",
    "    elif len(missing_genes)>0:\n",
    "        logger.warning(\n",
    "            f\"Genes to perturb {missing_genes} are not in token dictionary.\")\n",
    "    tokens_to_perturb = [gene_token_dict.get(gene) for gene in genes_to_perturb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc453e-822c-4aec-b663-872bcc509d45",
   "metadata": {},
   "source": [
    "### 2. perturb-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f46c25e-bc3e-43ba-a857-ce6e8a7fac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/nfs/xz/geneformer/Geneformer34m/examples/pretraining_new_model/output_own/models/230813_170132_geneformer_30M_L12_emb512_SL2048_E3_B12_LR0.0005_LSlinear_WU10000_Oadamw_DS64/models and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of control: 4475\n",
      "The count of stimulated: 1025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'condition', 'length'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_directory = '/mnt/nfs/xz/diffusion/db/Diffusion-BERT/model_out/230901_025119_model_name_gene_lr_5e-06_seed_42_numsteps_128_sample_Categorical_schedule_mutual_hybridlambda_0.01_wordfreqlambda_0.3_fromscratch_False_timestep_none_ckpts/best_0_14999.th' #diffusion12L\n",
    "model = load_model(model_type, num_classes, model_directory)\n",
    "layer_to_quant = quant_layers(model)+emb_layer #取哪一层的embedding\n",
    "\n",
    "data_path = '/mnt/nfs/wbzhang/data/perturber/experiment/data/dixit/tokenized_dixit.dataset'\n",
    "raw_data = load_from_disk(data_path)\n",
    "control_df = raw_data.filter(lambda x: x['condition'] == 'control')\n",
    "stimulated_df = raw_data.filter(lambda x: x['condition'] == 'YY1')\n",
    "print('The count of control:', len(control_df))\n",
    "print('The count of stimulated:', len(stimulated_df))\n",
    "\n",
    "filtered_input_data = concatenate_datasets([random_select(control_df), random_select(stimulated_df)])\n",
    "filtered_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370ad2a7-a775-48d8-bdcc-a8c7e25dd59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cos between control and YY1: tensor([0.9996], device='cuda:0')\n",
      "The size of filtered_input_data: 500\n"
     ]
    }
   ],
   "source": [
    "# cell_states_to_model is Not None\n",
    "state_name = cell_states_to_model[\"state_key\"]\n",
    "state_values = filtered_input_data[state_name] # 所有state的值\n",
    "for value in get_possible_states(cell_states_to_model):\n",
    "    if value not in state_values:\n",
    "        logger.error(\n",
    "            f\"{value} is not present in the dataset's {state_name} attribute.\")\n",
    "        raise\n",
    "downsampled_data = downsample_and_sort(filtered_input_data, max_ncells)\n",
    "\n",
    "# 拿来做对比的embedding\n",
    "state_embs_dict = get_cell_state_avg_embs(model,\n",
    "                                          downsampled_data,\n",
    "                                          cell_states_to_model,\n",
    "                                          layer_to_quant,\n",
    "                                          pad_token_id,\n",
    "                                          forward_batch_size,\n",
    "                                          nproc)\n",
    "cos1 = torch.nn.CosineSimilarity(dim=1)\n",
    "print('The cos between control and YY1:', cos1(state_embs_dict['control'], state_embs_dict['YY1']))\n",
    "\n",
    "# filter for start state cells\n",
    "start_state = cell_states_to_model[\"start_state\"] # 从0状态开始\n",
    "def filter_for_origin(example):\n",
    "    return example[state_name] in [start_state]\n",
    "filtered_input_data = filtered_input_data.filter(filter_for_origin, num_proc=nproc) #只选择全部数据中对应start_state的数据\n",
    "\n",
    "#output_path_prefix = f\"{output_directory}in_silico_{perturb_type}_{output_prefix}_dict_1Kbatch\"\n",
    "model_input_size = get_model_input_size(model)\n",
    "cos_sims_dict = defaultdict(list)\n",
    "pickle_batch = -1\n",
    "filtered_input_data = downsample_and_sort(filtered_input_data, max_ncells)\n",
    "print('The size of filtered_input_data:', len(filtered_input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb9f443-34de-45fa-bae8-b3db17dc69bd",
   "metadata": {},
   "source": [
    "### 3. In_silico_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0510d24-377f-4dfd-b219-f1a9b120e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afccd1831374c138694beb3b99de3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=16):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'condition', 'length'],\n",
       "    num_rows: 297\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'delete'\n",
    "min_genes = len(tokens_to_perturb)\n",
    "def if_has_tokens_to_perturb(example):\n",
    "    return (len(set(example[\"input_ids\"]).intersection(tokens_to_perturb))>=min_genes)\n",
    "filtered_input_data = filtered_input_data.filter(if_has_tokens_to_perturb, num_proc=nproc)\n",
    "if len(filtered_input_data) == 0:\n",
    "    logger.error(\n",
    "            \"No cells in dataset contain all genes to perturb as a group.\")\n",
    "    raise\n",
    "filtered_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db324ed-eeb4-433b-bb52-140c65993cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1784d1395d94460b36f862edbaafa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#选择cell的index\n",
    "if cell_inds_to_perturb != \"all\":\n",
    "    if cell_inds_to_perturb[\"start\"] >= len(filtered_input_data):\n",
    "        logger.error(\"cell_inds_to_perturb['start'] is larger than the filtered dataset.\")\n",
    "        raise\n",
    "    if cell_inds_to_perturb[\"end\"] > len(filtered_input_data):\n",
    "        logger.warning(\"cell_inds_to_perturb['end'] is larger than the filtered dataset. \\\n",
    "                       Setting to the end of the filtered dataset.\")\n",
    "        cell_inds_to_perturb[\"end\"] = len(filtered_input_data)\n",
    "    filtered_input_data = filtered_input_data.select([i for i in range(cell_inds_to_perturb[\"start\"], cell_inds_to_perturb[\"end\"])])\n",
    "#cell_inds_to_perturb == \"all\"\n",
    "# perturb_group == True\n",
    "def make_group_perturbation_batch(example):\n",
    "    example_input_ids = example[\"input_ids\"]\n",
    "    example[\"tokens_to_perturb\"] = tokens_to_perturb\n",
    "    indices_to_perturb = [example_input_ids.index(token) if token in example_input_ids else None for token in tokens_to_perturb]\n",
    "    indices_to_perturb = [item for item in indices_to_perturb if item is not None]\n",
    "    if len(indices_to_perturb) > 0:\n",
    "        example[\"perturb_index\"] = indices_to_perturb\n",
    "    else:\n",
    "        # -100 indicates tokens to overexpress are not present in rank value encoding\n",
    "        example[\"perturb_index\"] = [-100] #如果没有出现就是-100\n",
    "    if perturb_type == \"delete\":\n",
    "        example = delete_indices(example)\n",
    "    elif perturb_type == \"overexpress\":\n",
    "        example = overexpress_tokens(example) \n",
    "    return example\n",
    "    \n",
    "perturbation_batch = filtered_input_data.map(make_group_perturbation_batch, num_proc=nproc) # 如果gene在里面，就往前调，如果没有，就直接加在前面\n",
    "indices_to_perturb = perturbation_batch[\"perturb_index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8b176-c3b3-4e26-9c8e-9711aa4e3c54",
   "metadata": {},
   "source": [
    "### 4. quant_cos_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcf8f82-fd2b-4d3c-b243-82f2f3b9ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36440acecd843929d13a7a1d91cf874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_emb = filtered_input_data #只有这一个参数需要去特别指定 #原始的perturb矩阵\n",
    "cos = torch.nn.CosineSimilarity(dim=2)\n",
    "total_batch_length = len(perturbation_batch)\n",
    "if ((total_batch_length-1)/forward_batch_size).is_integer():\n",
    "    forward_batch_size = forward_batch_size-1\n",
    "# cell_states_to_model is Not None\n",
    "possible_states = get_possible_states(cell_states_to_model) #可能的所有状态\n",
    "cos_sims_vs_alt_dict = dict(zip(possible_states,[[] for i in range(len(possible_states))]))\n",
    "#百分比修改\n",
    "cos_sims_vs_alt_dict_percent = dict(zip(possible_states,[[] for i in range(len(possible_states))]))\n",
    "perturbation_batch = perturbation_batch.map(\n",
    "        measure_length, num_proc=nproc\n",
    "    ) #对perturb的input_ids重新计算length\n",
    "\n",
    "#开始取perturb embedding\n",
    "def compute_batch_embeddings(minibatch, _max_len = None):\n",
    "    minibatch_lengths = minibatch[\"length\"]\n",
    "    minibatch_length_set = set(minibatch_lengths)\n",
    "    max_len = model_input_size\n",
    "\n",
    "    if (len(minibatch_length_set) > 1) or (max(minibatch_length_set) > max_len):\n",
    "        needs_pad_or_trunc = True\n",
    "    else:\n",
    "        needs_pad_or_trunc = False\n",
    "        max_len = max(minibatch_length_set)\n",
    "\n",
    "\n",
    "    if needs_pad_or_trunc == True:\n",
    "        if _max_len is None:\n",
    "            max_len = min(max(minibatch_length_set), max_len)\n",
    "        else:\n",
    "            max_len = _max_len\n",
    "        def pad_or_trunc_example(example):\n",
    "            example[\"input_ids\"] = pad_or_truncate_encoding(example[\"input_ids\"], \n",
    "                                                           pad_token_id, \n",
    "                                                           max_len)\n",
    "            return example\n",
    "        minibatch = minibatch.map(pad_or_trunc_example, num_proc=nproc)\n",
    "        \n",
    "    minibatch.set_format(type=\"torch\")\n",
    "    \n",
    "    input_data_minibatch = minibatch[\"input_ids\"]\n",
    "    attention_mask = gen_attention_mask(minibatch, max_len)\n",
    "    \n",
    "    # extract embeddings for perturbation minibatch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids = input_data_minibatch.to(\"cuda\"),\n",
    "            attention_mask = attention_mask\n",
    "        )\n",
    "\n",
    "    return outputs, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8c1ea0-ce87-473f-a3a5-c853794f9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61835/2221873459.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_minibatch_lengths = torch.tensor(original_minibatch[\"length\"], device=\"cuda\")\n",
      "/tmp/ipykernel_61835/2221873459.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  minibatch_lengths = torch.tensor(perturbation_minibatch[\"length\"], device=\"cuda\")\n",
      "/tmp/ipykernel_61835/2221873459.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(original_minibatch_lengths, device=\"cuda\"),\n",
      "/tmp/ipykernel_61835/2221873459.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(minibatch_lengths, device=\"cuda\"),\n",
      "/tmp/ipykernel_61835/2221873459.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(original_minibatch_lengths, device=\"cuda\"),\n",
      "/tmp/ipykernel_61835/2221873459.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(minibatch_lengths, device=\"cuda\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2047, 512])\n",
      "torch.Size([100, 2047, 512])\n",
      "torch.Size([100, 2047, 512])\n",
      "torch.Size([100, 2047, 512])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa7fdb71c7049a196cfb484f06e4788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d711d4ef062b4de0ae507c71be48eef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/97 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 2047, 512])\n",
      "torch.Size([97, 2047, 512])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, total_batch_length, forward_batch_size):\n",
    "    max_range = min(i+forward_batch_size, total_batch_length)\n",
    "\n",
    "    perturbation_minibatch = perturbation_batch.select([i for i in range(i, max_range)])\n",
    "    outputs, mini_max_len = compute_batch_embeddings(perturbation_minibatch)\n",
    "\n",
    "    if len(indices_to_perturb)>1:\n",
    "        minibatch_emb = torch.squeeze(outputs.hidden_states[layer_to_quant])\n",
    "    else:\n",
    "        minibatch_emb = outputs.hidden_states[layer_to_quant]\n",
    "    \n",
    "    # perturb_group == True:\n",
    "    original_minibatch = original_emb.select([i for i in range(i, max_range)])\n",
    "    original_outputs, orig_max_len = compute_batch_embeddings(original_minibatch)\n",
    "    if len(indices_to_perturb)>1:\n",
    "        original_minibatch_emb = torch.squeeze(original_outputs.hidden_states[layer_to_quant])\n",
    "    else:\n",
    "        original_minibatch_emb = original_outputs.hidden_states[layer_to_quant]\n",
    "\n",
    "    if len(tokens_to_perturb) == 1:\n",
    "        indices_to_perturb_minibatch = [idx if idx != [-100] else [orig_max_len - 1]\n",
    "                                        for idx in indices_to_perturb[i:max_range]]\n",
    "    else:\n",
    "        num_perturbed = len(tokens_to_perturb)\n",
    "        indices_to_perturb_minibatch = []\n",
    "        end_range = [i for i in range(orig_max_len - len(tokens_to_perturb), orig_max_len)]\n",
    "        for idx in indices_to_perturb[i:max_range]:\n",
    "            if idx == [-100]:\n",
    "                indices_to_perturb_minibatch.append(end_range)\n",
    "            elif len(idx) < len(tokens_to_perturb):\n",
    "                # 代码不对 有修改\n",
    "                indices_to_perturb_minibatch.append(idx + end_range[-num_perturbed+len(idx):])\n",
    "            else:\n",
    "                indices_to_perturb_minibatch.append(idx)\n",
    "    \n",
    "    original_minibatch_emb = remove_indices_from_emb_batch(original_minibatch_emb, \n",
    "                                                           indices_to_perturb_minibatch, \n",
    "                                                           gene_dim=1)\n",
    "\n",
    "    original_minibatch_lengths = torch.tensor(original_minibatch[\"length\"], device=\"cuda\")\n",
    "    minibatch_lengths = torch.tensor(perturbation_minibatch[\"length\"], device=\"cuda\")\n",
    "    print(original_minibatch_emb.shape)\n",
    "    print(minibatch_emb.shape)\n",
    "    for state in possible_states:\n",
    "        '''\n",
    "        cos_sim_shift:有大量修改，不取mean，每个cell 的每个gene算cos，先整合起来\n",
    "        '''\n",
    "        cos_sims_vs_alt_dict[state] += cos_sim_shift_ipsc(original_minibatch_emb, \n",
    "                                                    minibatch_emb, \n",
    "                                                    state_embs_dict[state],\n",
    "                                                    perturb_group,\n",
    "                                                    torch.tensor(original_minibatch_lengths, device=\"cuda\"),\n",
    "                                                    torch.tensor(minibatch_lengths, device=\"cuda\"),\n",
    "                                                    perturb_method='cell')[0]\n",
    "        cos_sims_vs_alt_dict_percent[state] += cos_sim_shift_ipsc(original_minibatch_emb, \n",
    "                                                    minibatch_emb, \n",
    "                                                    state_embs_dict[state],\n",
    "                                                    perturb_group,\n",
    "                                                    torch.tensor(original_minibatch_lengths, device=\"cuda\"),\n",
    "                                                    torch.tensor(minibatch_lengths, device=\"cuda\"),\n",
    "                                                    perturb_method='cell')[1]\n",
    "        \n",
    "    del outputs\n",
    "    del minibatch_emb\n",
    "    del mini_max_len\n",
    "    del original_minibatch\n",
    "    del original_outputs\n",
    "    del orig_max_len\n",
    "    del original_minibatch_emb\n",
    "    del original_minibatch_lengths\n",
    "    del perturbation_minibatch\n",
    "    del minibatch_lengths\n",
    "# cell_states_to_model is not None\n",
    "for state in possible_states:\n",
    "    cos_sims_vs_alt_dict[state] = torch.cat(cos_sims_vs_alt_dict[state])\n",
    "    cos_sims_vs_alt_dict_percent[state] = torch.cat(cos_sims_vs_alt_dict_percent[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a893ddea-b69a-4279-ae15-74575c54b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos shift: tensor(-1.0724e-05)\n"
     ]
    }
   ],
   "source": [
    "print('cos shift:', torch.mean(cos_sims_vs_alt_dict['YY1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW_geneformer",
   "language": "python",
   "name": "new_geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
