{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66455ab5-b254-4f28-9d21-3ca05c6c0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/wbzhang/geneformer-master/Geneformer/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/wbzhang/geneformer-master/Geneformer/myenv/lib/python3.8/site-packages/geneformer/__init__.py\n",
      "/mnt/nfs/wbzhang/geneformer-master/Geneformer/myenv/lib/python3.8/site-packages/geneformer/token_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import geneformer\n",
    "print(geneformer.__file__)\n",
    "import os\n",
    "GPU_NUMBER = [2]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "print(geneformer.tokenizer.TOKEN_DICTIONARY_FILE)\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import pickle\n",
    "import dill\n",
    "import subprocess\n",
    "import seaborn as sns; sns.set()\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers.training_args import TrainingArguments\n",
    "\n",
    "from geneformer import DataCollatorForCellClassification\n",
    "import scanpy as sc\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "160f01e6-7876-4335-b9e9-84886afe292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # calculate accuracy and macro f1 using sklearn's function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\n",
    "      'accuracy': acc,\n",
    "      'macro_f1': macro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8850fa-2b3c-47d0-abf7-818ee6b55d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16): 100%|███████████████████████████████████████████████████████████████████████████████| 13342/13342 [00:00<00:00, 52634.29 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/nfs/xz/geneformer/Geneformer34m/examples/pretraining_new_model/output_own/models/230813_170132_geneformer_30M_L12_emb512_SL2048_E3_B12_LR0.0005_LSlinear_WU10000_Oadamw_DS64/models and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k_final/Model/geneformer/we_12L_finetune/fold0_model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/wbzhang/geneformer-master/Geneformer/myenv/lib/python3.8/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction result of 0 fold:\n",
      "{'accuracy': 0.025183630640083946, 'macro_f1': 0.02372621801398035}\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k_final/data/geneformer/5_fold_arrow/'\n",
    "pretrain_model_path = '/mnt/nfs/xz/geneformer/Geneformer34m/examples/pretraining_new_model/output_own/models/230813_170132_geneformer_30M_L12_emb512_SL2048_E3_B12_LR0.0005_LSlinear_WU10000_Oadamw_DS64/models'\n",
    "finetune_path = \"/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k_final/Model/geneformer/we_12L_finetune/\"\n",
    "fold_number = 5\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    fold_path = folder_path + 'fold' + str(i) + '_test_arrow.dataset'\n",
    "    test_dataset = load_from_disk(fold_path)\n",
    "    total = test_dataset.rename_column(\"cell_type\",\"label\")\n",
    "    total = total.remove_columns(\"organ\")\n",
    "    target_names = list(Counter(total[\"label\"]).keys())\n",
    "    target_name_id_dict = dict(zip(target_names,[i for i in range(len(target_names))]))\n",
    "\n",
    "    def classes_to_ids(example):\n",
    "        example[\"label\"] = target_name_id_dict[example[\"label\"]]\n",
    "        return example\n",
    "    labeled_total = total.map(classes_to_ids, num_proc=16)\n",
    "    testset = labeled_total\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(pretrain_model_path, \n",
    "                                                  num_labels=len(target_name_id_dict.keys()),\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False).to(\"cuda\")\n",
    "    finetune_dir = finetune_path + 'fold' + str(i) + '_model/pytorch_model.bin'\n",
    "    print(finetune_dir)\n",
    "    checkpoint = torch.load(finetune_dir)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=DataCollatorForCellClassification(),\n",
    "    compute_metrics=compute_metrics\n",
    "    )\n",
    "    predictions = trainer.predict(testset)\n",
    "    print('The prediction result of '+str(i)+' fold:')\n",
    "    print(compute_metrics(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797de518-7fa5-4b12-aee9-67b32def3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c4d5610-eadb-4353-a93e-89f652709274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2664529 , -1.0617732 , -0.97898096, ..., -2.1967382 ,\n",
       "        -2.2737122 , -3.4333665 ],\n",
       "       [-2.2471647 , -0.5895008 ,  0.4020873 , ..., -2.461241  ,\n",
       "        -2.33209   , -4.020839  ],\n",
       "       [ 1.5664858 , -1.843969  ,  0.6841839 , ..., -2.5160458 ,\n",
       "        -2.4820912 , -3.8923113 ],\n",
       "       ...,\n",
       "       [-1.2024128 , -2.6249254 , -2.2684877 , ..., -2.0823631 ,\n",
       "        -1.6634806 , -2.099236  ],\n",
       "       [-2.5956922 ,  6.1489105 , -1.2428662 , ..., -1.2053187 ,\n",
       "        -2.6050742 , -2.2316387 ],\n",
       "       [-1.0306069 , -1.6278262 , -0.44036603, ..., -2.3900173 ,\n",
       "        -2.445148  , -3.801106  ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd06eaaa-3d50-4a4d-bb85-55c1c86614cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'label', 'length'],\n",
       "    num_rows: 13342\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eea8924-d86e-4464-b7ac-fa150df3ffce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'label', 'length'],\n",
       "    num_rows: 18358\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "folder_path = '/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k'\n",
    "with open(folder_path+ '/'+'test.pkl','rb') as f:\n",
    "    test = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3fe811-9900-4ad5-a412-915ae259cbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /mnt/nfs/xz/geneformer/Geneformer34m/examples/pretraining_new_model/output_own/models/230813_170132_geneformer_30M_L12_emb512_SL2048_E3_B12_LR0.0005_LSlinear_WU10000_Oadamw_DS64/models and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k_final/data/geneformer/5_fold_arrow/'\n",
    "pretrain_model_path = '/mnt/nfs/xz/geneformer/Geneformer34m/examples/pretraining_new_model/output_own/models/230813_170132_geneformer_30M_L12_emb512_SL2048_E3_B12_LR0.0005_LSlinear_WU10000_Oadamw_DS64/models'\n",
    "finetune_path = \"/mnt/nfs/wbzhang/data/celltype_annotation/zheng68k_final/Model/geneformer/we_12L_finetune/\"\n",
    "fold_number = 5\n",
    "for i in range(1):\n",
    "    fold_path = folder_path + 'fold' + str(i) + '_test_arrow.dataset'\n",
    "    test_dataset = load_from_disk(fold_path)\n",
    "    total = test_dataset.rename_column(\"cell_type\",\"label\")\n",
    "    total = total.remove_columns(\"organ\")\n",
    "    target_names = list(Counter(total[\"label\"]).keys())\n",
    "    target_name_id_dict = dict(zip(target_names,[i for i in range(len(target_names))]))\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(pretrain_model_path, \n",
    "                                                  num_labels=len(target_name_id_dict.keys()),\n",
    "                                                  output_attentions = False,\n",
    "                                                  output_hidden_states = False).to(\"cuda\")\n",
    "\n",
    "    def classes_to_ids(example):\n",
    "        example[\"label\"] = target_name_id_dict[example[\"label\"]]\n",
    "        return example\n",
    "    labeled_total = total.map(classes_to_ids, num_proc=16)\n",
    "    testset = labeled_total\n",
    "    '''\n",
    "    finetune_dir = finetune_path + 'fold' + str(i) + '_model/pytorch_model.bin'\n",
    "    checkpoint = torch.load(finetune_dir)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=DataCollatorForCellClassification(),\n",
    "    compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    predictions = trainer.predict(testset)\n",
    "    print('The prediction result of '+str(i)+' fold:')\n",
    "    print(compute_metrics(predictions))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e63f4-582c-4819-a552-e20faf30f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e40545a0-3780-4158-a0c5-4db4f6d8b120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'label', 'length'],\n",
       "    num_rows: 13342\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer_ours",
   "language": "python",
   "name": "geneformer_ours"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
